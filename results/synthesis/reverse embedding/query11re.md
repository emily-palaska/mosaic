# Reverse Embedding Code Synthesis
Query `Run out‑of‑core classification on large dataset.`
## Script Variables
- plt:<br>
>plt is a module in Python that is used for creating plots. It is a part of the Python
- MiniBatchKMeans:<br>
>MiniBatchKMeans is a clustering algorithm that uses a mini-batch gradient descent algorithm to find the
- this_centroid:<br>
>This variable is a list of the centroids of the clusters generated by the BIRCH algorithm. It
- zip:<br>
>It is a function that creates a list of tuples from a list of lists.
- colors_:<br>
>Colors_ is a list of colors used to color the points in the scatter plot. It is a
- k:<br>
>k is the number of clusters in the dataset. It is used to determine the number of centroids that
- mask:<br>
>The variable mask is a list of boolean values that represent the membership of each data point in a particular
- print:<br>
>print() is a python function that prints the output to the console. It is used to display the
- fig:<br>
>fig is a matplotlib figure object which is used to create a plot. The figure object is used to
- np:<br>
>np is a python library that provides a large number of mathematical functions and data structures. It is used
- X:<br>
>X is a 2D array containing the data points. It is used to plot the data points
- ax:<br>
>The variable ax is a matplotlib axis object. It is used to plot the data points in the figure
- col:<br>
>col is a color that is used to represent the different clusters. It is used to color the points
- cpu_count:<br>
>The variable cpu_count is a Python function that returns the number of CPUs available on the system. It
- t_mini_batch:<br>
>t_mini_batch is a variable that is used to measure the time taken by the MiniBatchKMeans
- mbk_means_labels_unique:<br>
>The variable mbk_means_labels_unique is a unique list of labels that are assigned to each data point
- range:<br>
>The variable range is the range of values that a variable can take on. In this case, the
- n_clusters:<br>
>It is a variable that represents the number of clusters in the data set. It is used to determine
- time:<br>
>The variable time is used to measure the time taken by the script to execute the Birch model. It
## Synthesis Blocks
### notebooks/dataset2/clustering/plot_birch_vs_minibatchkmeans.ipynb
CONTEXT:   Compare BIRCH and MiniBatchKMeans  This example compares the timing of BIRCH (with and without the global clustering step) and
MiniBatchKMeans on a synthetic dataset having 25,000 samples and 2 features generated using make_blobs.  Both ``MiniBatchKMeans`` and ``BIRCH`` are
very scalable algorithms and could run efficiently on hundreds of thousands or even millions of datapoints. We chose to limit the dataset size of this
example in the interest of keeping our Continuous Integration resource usage reasonable but the interested reader might enjoy editing this script to
rerun it with a larger value for `n_samples`.  If ``n_clusters`` is set to None, the data is reduced from 25,000 samples to a set of 158 clusters.
This can be viewed as a preprocessing step before the final (global) clustering step that further reduces these 158 clusters to 100 clusters.
COMMENT: Compute clustering with MiniBatchKMeans.
```python
MiniBatchKMeans = MiniBatchKMeans(
    init="k-means++",
    n_clusters=100,
    batch_size=256 * cpu_count(),
    n_init=10,
    max_no_improvement=10,
    verbose=0,
    random_state=0,
)
t_mini_batch = time()
MiniBatchKMeans.fit(X)
t_mini_batch = time() - t_mini_batch
print("Time taken to run MiniBatchKMeans %0.2f seconds" % t_mini_batch)
mbk_means_labels_unique = np.unique(MiniBatchKMeans.labels_)
ax = fig.add_subplot(1, 3, 3)
for this_centroid, k, col in zip(MiniBatchKMeans.cluster_centers_, range(n_clusters), colors_):
    mask = MiniBatchKMeans.labels_ == k
    ax.scatter(X[mask, 0], X[mask, 1], marker=".", c="w", edgecolor=col, alpha=0.5)
    ax.scatter(this_centroid[0], this_centroid[1], marker="+", c="k", s=25)
ax.set_xlim([-25, 25])
ax.set_ylim([-25, 25])
ax.set_title("MiniBatchKMeans")
ax.set_autoscaley_on(False)
plt.show()
```

## Code Concatenation
```python
MiniBatchKMeans = MiniBatchKMeans(
    init="k-means++",
    n_clusters=100,
    batch_size=256 * cpu_count(),
    n_init=10,
    max_no_improvement=10,
    verbose=0,
    random_state=0,
)
t_mini_batch = time()
MiniBatchKMeans.fit(X)
t_mini_batch = time() - t_mini_batch
print("Time taken to run MiniBatchKMeans %0.2f seconds" % t_mini_batch)
mbk_means_labels_unique = np.unique(MiniBatchKMeans.labels_)
ax = fig.add_subplot(1, 3, 3)
for this_centroid, k, col in zip(MiniBatchKMeans.cluster_centers_, range(n_clusters), colors_):
    mask = MiniBatchKMeans.labels_ == k
    ax.scatter(X[mask, 0], X[mask, 1], marker=".", c="w", edgecolor=col, alpha=0.5)
    ax.scatter(this_centroid[0], this_centroid[1], marker="+", c="k", s=25)
ax.set_xlim([-25, 25])
ax.set_ylim([-25, 25])
ax.set_title("MiniBatchKMeans")
ax.set_autoscaley_on(False)
plt.show()
```
