# String Code Synthesis
Query `Split multilabel dataset into train and test.`
## Script Variables
- y_train:<br>
>y_train is a numpy array of size (n_samples, 1) containing the target values of
- X_test:<br>
>X_test is a numpy array containing the test data. It is used to plot the test data points
- X_train:<br>
>X_train is a pandas dataframe containing the features of the dataset. It is a matrix of shape (
- train_test_split:<br>
>It is a function that splits the dataset into training and testing sets. The random_state parameter is used
- X:<br>
>X is a numpy array of shape (1000, 1) containing random numbers between 0
- y_test:<br>
>It is a test set of the data used to evaluate the model's performance. It is used to
- y:<br>
>The variable y is a random variable that represents the noise in the data. It is generated by adding
## Synthesis Blocks
### notebooks/dataset2/dataset_examples/plot_random_multilabel_dataset.ipynb
CONTEXT:   Plot randomly generated multilabel dataset  This illustrates the :func:`~sklearn.datasets.make_multilabel_classification` dataset
generator. Each sample consists of counts of two features (up to 50 in total), which are differently distributed in each of two classes.  Points are
labeled as follows, where Y means the class is present:  =====  =====  =====  ======   1      2      3    Color =====  =====  =====  ======   Y      N
N    Red   N      Y      N    Blue   N      N      Y    Yellow   Y      Y      N    Purple   Y      N      Y    Orange   Y      Y      N    Green   Y
Y      Y    Brown =====  =====  =====  ======  A star marks the expected sample for each class; its size reflects the probability of selecting that
class label.  The left and right examples highlight the ``n_labels`` parameter: more of the samples in the right plot have 2 or 3 labels.  Note that
this two-dimensional example is very degenerate: generally the number of features would be much greater than the "document length", while here we have
much larger documents than vocabulary. Similarly, with ``n_classes > n_features``, it is much less likely that a feature distinguishes a particular
class.  COMMENT: red
```python
"#FF3333",
```

### notebooks/dataset2/ensemble_methods/plot_gradient_boosting_quantile.ipynb
CONTEXT: Split into train, test datasets:   COMMENT:
```python
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)
```

## Code Concatenation
```python
"#FF3333",
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)
```
